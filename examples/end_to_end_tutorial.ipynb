{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MolecuGen: End-to-End Tutorial\n",
    "\n",
    "This notebook provides a comprehensive tutorial for using MolecuGen to train molecular generation models and generate drug-like molecules.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Installation](#setup)\n",
    "2. [Data Preparation](#data-preparation)\n",
    "3. [Model Training](#model-training)\n",
    "4. [Molecular Generation](#molecular-generation)\n",
    "5. [Constraint-Based Generation](#constraint-generation)\n",
    "6. [Evaluation and Analysis](#evaluation)\n",
    "7. [Visualization](#visualization)\n",
    "8. [Performance Benchmarking](#benchmarking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation {#setup}\n",
    "\n",
    "First, let's install the required dependencies and import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "# !pip install torch torch-geometric rdkit-pypi numpy scipy matplotlib seaborn pandas\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MolecuGen modules\n",
    "from src.data.molecular_dataset import MolecularDataset\n",
    "from src.data.smiles_processor import SMILESProcessor\n",
    "from src.data.feature_extractor import FeatureExtractor\n",
    "from src.training.trainer import Trainer\n",
    "from src.generate.molecular_generator import MolecularGenerator\n",
    "from src.generate.constraint_filter import ConstraintFilter\n",
    "from src.evaluate.molecular_evaluator import MolecularEvaluator\n",
    "\n",
    "print(\"MolecuGen modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation {#data-preparation}\n",
    "\n",
    "Let's prepare a dataset of molecules for training. We'll use a subset of ZINC15 molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample SMILES data (in practice, load from file)\n",
    "sample_smiles = [\n",
    "    \"CCO\",  # Ethanol\n",
    "    \"CC(=O)O\",  # Acetic acid\n",
    "    \"CC(=O)Nc1ccc(O)cc1\",  # Acetaminophen\n",
    "    \"CC(C)Cc1ccc(C(C)C(=O)O)cc1\",  # Ibuprofen\n",
    "    \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\",  # Caffeine\n",
    "    \"CC1=CC=C(C=C1)C(=O)O\",  # p-Toluic acid\n",
    "    \"C1=CC=C(C=C1)C(=O)O\",  # Benzoic acid\n",
    "    \"CC(C)(C)NCC(C1=CC(=C(C=C1)O)CO)O\",  # Salbutamol\n",
    "    \"CC1=C(C(=O)N(N1C)C2=CC=CC=C2)C(=O)NCCCCOC3=CC=CC=C3\",  # Example drug-like molecule\n",
    "    \"COC1=C(C=CC(=C1)CC2COC(=O)C2)O\"  # Another drug-like molecule\n",
    "]\n",
    "\n",
    "# In practice, load from file:\n",
    "# with open('data/zinc15_subset.smi', 'r') as f:\n",
    "#     sample_smiles = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"Loaded {len(sample_smiles)} sample molecules\")\n",
    "for i, smiles in enumerate(sample_smiles[:5]):\n",
    "    print(f\"{i+1}: {smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processors\n",
    "smiles_processor = SMILESProcessor(\n",
    "    add_self_loops=False,\n",
    "    explicit_hydrogens=False,\n",
    "    sanitize=True\n",
    ")\n",
    "\n",
    "feature_extractor = FeatureExtractor(\n",
    "    use_chirality=True,\n",
    "    use_partial_charge=False,  # Faster without partial charges\n",
    "    max_atomic_num=100\n",
    ")\n",
    "\n",
    "print(f\"Atom feature dimensions: {feature_extractor.get_atom_features_dim()}\")\n",
    "print(f\"Bond feature dimensions: {feature_extractor.get_bond_features_dim()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create molecular dataset\n",
    "dataset = MolecularDataset(\n",
    "    smiles_list=sample_smiles,\n",
    "    smiles_processor=smiles_processor,\n",
    "    feature_extractor=feature_extractor,\n",
    "    max_nodes=50\n",
    ")\n",
    "\n",
    "print(f\"Created dataset with {len(dataset)} valid molecules\")\n",
    "\n",
    "# Examine a sample molecule\n",
    "sample_data = dataset[0]\n",
    "print(f\"\\nSample molecule:\")\n",
    "print(f\"SMILES: {sample_data.smiles}\")\n",
    "print(f\"Nodes: {sample_data.x.shape[0]}\")\n",
    "print(f\"Edges: {sample_data.edge_index.shape[1]}\")\n",
    "print(f\"Node features shape: {sample_data.x.shape}\")\n",
    "print(f\"Edge features shape: {sample_data.edge_attr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training {#model-training}\n",
    "\n",
    "Now let's train a small diffusion model on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = {\n",
    "    'name': 'tutorial_model',\n",
    "    'output_dir': 'tutorial_experiments',\n",
    "    \n",
    "    'model': {\n",
    "        'type': 'diffusion',\n",
    "        'hidden_dim': 128,  # Small model for tutorial\n",
    "        'num_layers': 3,\n",
    "        'dropout': 0.1,\n",
    "        'num_timesteps': 100,  # Fewer timesteps for faster training\n",
    "        'beta_schedule': 'cosine',\n",
    "        'max_nodes': 50\n",
    "    },\n",
    "    \n",
    "    'training': {\n",
    "        'batch_size': 4,  # Small batch for small dataset\n",
    "        'num_epochs': 20,  # Few epochs for tutorial\n",
    "        'learning_rate': 1e-3,\n",
    "        'weight_decay': 1e-5,\n",
    "        'gradient_clip': 1.0,\n",
    "        'patience': 10,\n",
    "        'save_every': 5,\n",
    "        'validate_every': 1,\n",
    "        \n",
    "        'optimizer': {\n",
    "            'type': 'adam',\n",
    "            'betas': [0.9, 0.999]\n",
    "        },\n",
    "        \n",
    "        'scheduler': {\n",
    "            'type': 'cosine',\n",
    "            'eta_min': 1e-6\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'data': {\n",
    "        'train_split': 0.7,\n",
    "        'val_split': 0.2,\n",
    "        'test_split': 0.1\n",
    "    },\n",
    "    \n",
    "    'logging': {\n",
    "        'level': 'INFO',\n",
    "        'use_tensorboard': False,  # Disable for tutorial\n",
    "        'use_wandb': False\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Training configuration created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "trainer = Trainer(config=config, device=device)\n",
    "\n",
    "# Setup training components\n",
    "print(\"Setting up data...\")\n",
    "trainer.setup_data(dataset)\n",
    "\n",
    "print(\"Setting up model...\")\n",
    "trainer.setup_model()\n",
    "\n",
    "print(\"Setting up optimizer...\")\n",
    "trainer.setup_optimizer()\n",
    "\n",
    "print(\"Setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "results = trainer.train()\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best validation loss: {results['best_val_loss']:.6f}\")\n",
    "print(f\"Total epochs: {results['total_epochs']}\")\n",
    "print(f\"Training time: {results['total_time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "history = trainer.training_history\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot losses\n",
    "axes[0].plot(history['epochs'], history['train_losses'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['epochs'], history['val_losses'], label='Validation Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Training Progress')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot learning rate\n",
    "axes[1].plot(history['epochs'], history['learning_rates'], color='red', marker='d')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Learning Rate')\n",
    "axes[1].set_title('Learning Rate Schedule')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Molecular Generation {#molecular-generation}\n",
    "\n",
    "Now let's use our trained model to generate new molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "checkpoint_path = Path(config['output_dir']) / \"checkpoints\" / \"best_model.pt\"\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    generator = MolecularGenerator.from_checkpoint(checkpoint_path, device=device)\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "    # Use the current model from trainer\n",
    "    generator = MolecularGenerator(\n",
    "        model=trainer.model,\n",
    "        smiles_processor=smiles_processor,\n",
    "        device=device\n",
    "    )\n",
    "    print(\"Using current model from trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate molecules with different temperatures\n",
    "temperatures = [0.5, 1.0, 1.5, 2.0]\n",
    "generation_results = {}\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\nGenerating with temperature {temp}...\")\n",
    "    molecules = generator.generate(\n",
    "        num_molecules=20,\n",
    "        temperature=temp,\n",
    "        batch_size=5,\n",
    "        max_attempts=5\n",
    "    )\n",
    "    \n",
    "    generation_results[temp] = molecules\n",
    "    print(f\"Generated {len(molecules)} molecules\")\n",
    "    \n",
    "    # Show first few molecules\n",
    "    for i, smiles in enumerate(molecules[:3]):\n",
    "        print(f\"  {i+1}: {smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze generation statistics\n",
    "stats = generator.get_generation_statistics()\n",
    "print(\"Generation Statistics:\")\n",
    "print(f\"Total generated: {stats['total_generated']}\")\n",
    "print(f\"Valid molecules: {stats['valid_molecules']}\")\n",
    "print(f\"Unique molecules: {stats['unique_molecules']}\")\n",
    "print(f\"Validity rate: {stats['validity_rate']:.2%}\")\n",
    "print(f\"Uniqueness rate: {stats['uniqueness_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Constraint-Based Generation {#constraint-generation}\n",
    "\n",
    "Let's generate molecules that satisfy drug-likeness constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define drug-likeness constraints\n",
    "drug_constraints = {\n",
    "    'lipinski': True,           # Lipinski's Rule of Five\n",
    "    'qed_threshold': 0.3,       # Minimum drug-likeness score (lowered for small dataset)\n",
    "    'mw_range': [100, 500],     # Molecular weight range\n",
    "    'logp_range': [-2, 5]       # LogP range\n",
    "}\n",
    "\n",
    "print(\"Drug-likeness constraints:\")\n",
    "for key, value in drug_constraints.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate drug-like molecules\n",
    "print(\"Generating drug-like molecules...\")\n",
    "drug_molecules = generator.generate_with_constraints(\n",
    "    num_molecules=15,\n",
    "    constraints=drug_constraints,\n",
    "    temperature=1.2,\n",
    "    max_attempts=10,\n",
    "    iterative_filtering=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(drug_molecules)} drug-like molecules:\")\n",
    "for i, smiles in enumerate(drug_molecules):\n",
    "    print(f\"{i+1:2d}: {smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze constraint satisfaction\n",
    "constraint_filter = ConstraintFilter()\n",
    "\n",
    "print(\"\\nConstraint Analysis:\")\n",
    "for i, smiles in enumerate(drug_molecules[:5]):  # Analyze first 5\n",
    "    print(f\"\\nMolecule {i+1}: {smiles}\")\n",
    "    \n",
    "    # Check individual Lipinski rules\n",
    "    lipinski_results = constraint_filter.check_lipinski_rule(smiles)\n",
    "    print(f\"  Lipinski rules: MW={lipinski_results['mw_pass']}, \"\n",
    "          f\"LogP={lipinski_results['logp_pass']}, \"\n",
    "          f\"HBD={lipinski_results['hbd_pass']}, \"\n",
    "          f\"HBA={lipinski_results['hba_pass']}\")\n",
    "    \n",
    "    # Calculate QED score\n",
    "    qed_score = constraint_filter.calculate_qed_score(smiles)\n",
    "    print(f\"  QED score: {qed_score:.3f}\" if qed_score else \"  QED score: N/A\")\n",
    "    \n",
    "    # Calculate molecular weight and LogP\n",
    "    mw = constraint_filter.calculate_molecular_weight(smiles)\n",
    "    logp = constraint_filter.calculate_logp(smiles)\n",
    "    print(f\"  MW: {mw:.1f}, LogP: {logp:.2f}\" if mw and logp else \"  Properties: N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation and Analysis {#evaluation}\n",
    "\n",
    "Let's comprehensively evaluate our generated molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all generated molecules for evaluation\n",
    "all_generated = []\n",
    "for temp_molecules in generation_results.values():\n",
    "    all_generated.extend(temp_molecules)\n",
    "all_generated.extend(drug_molecules)\n",
    "\n",
    "# Remove duplicates\n",
    "unique_generated = list(set(all_generated))\n",
    "print(f\"Total unique generated molecules: {len(unique_generated)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluator with training data as reference\n",
    "reference_molecules = sample_smiles  # Use original training data as reference\n",
    "evaluator = MolecularEvaluator(reference_molecules=reference_molecules)\n",
    "\n",
    "# Comprehensive evaluation\n",
    "evaluation_results = evaluator.evaluate(unique_generated)\n",
    "\n",
    "print(\"Basic Evaluation Metrics:\")\n",
    "print(f\"Validity: {evaluation_results['validity']:.2%}\")\n",
    "print(f\"Uniqueness: {evaluation_results['uniqueness']:.2%}\")\n",
    "print(f\"Novelty: {evaluation_results['novelty']:.2%}\")\n",
    "print(f\"Total molecules: {evaluation_results['total_molecules']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug-likeness evaluation\n",
    "drug_likeness_metrics = evaluator.compute_drug_likeness_metrics(unique_generated)\n",
    "\n",
    "print(\"\\nDrug-likeness Metrics:\")\n",
    "print(f\"Mean QED: {drug_likeness_metrics['mean_qed']:.3f}\")\n",
    "print(f\"Median QED: {drug_likeness_metrics['median_qed']:.3f}\")\n",
    "print(f\"Lipinski pass rate: {drug_likeness_metrics['lipinski_pass_rate']:.2%}\")\n",
    "print(f\"MW pass rate: {drug_likeness_metrics['mw_pass_rate']:.2%}\")\n",
    "print(f\"LogP pass rate: {drug_likeness_metrics['logp_pass_rate']:.2%}\")\n",
    "print(f\"HBD pass rate: {drug_likeness_metrics['hbd_pass_rate']:.2%}\")\n",
    "print(f\"HBA pass rate: {drug_likeness_metrics['hba_pass_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property distributions\n",
    "property_distributions = evaluator.compute_property_distributions(unique_generated)\n",
    "reference_distributions = evaluator.compute_property_distributions(reference_molecules)\n",
    "\n",
    "print(\"\\nProperty Distribution Statistics:\")\n",
    "properties = ['molecular_weight', 'logp', 'num_atoms', 'num_bonds']\n",
    "\n",
    "for prop in properties:\n",
    "    if prop in property_distributions and len(property_distributions[prop]) > 0:\n",
    "        gen_mean = np.mean(property_distributions[prop])\n",
    "        gen_std = np.std(property_distributions[prop])\n",
    "        \n",
    "        if prop in reference_distributions and len(reference_distributions[prop]) > 0:\n",
    "            ref_mean = np.mean(reference_distributions[prop])\n",
    "            ref_std = np.std(reference_distributions[prop])\n",
    "            print(f\"{prop}:\")\n",
    "            print(f\"  Generated: {gen_mean:.2f} ± {gen_std:.2f}\")\n",
    "            print(f\"  Reference: {ref_mean:.2f} ± {ref_std:.2f}\")\n",
    "        else:\n",
    "            print(f\"{prop}: {gen_mean:.2f} ± {gen_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization {#visualization}\n",
    "\n",
    "Let's create visualizations to better understand our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot property distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "properties = ['molecular_weight', 'logp', 'num_atoms', 'num_bonds']\n",
    "property_labels = ['Molecular Weight (Da)', 'LogP', 'Number of Atoms', 'Number of Bonds']\n",
    "\n",
    "for i, (prop, label) in enumerate(zip(properties, property_labels)):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    if prop in property_distributions and len(property_distributions[prop]) > 0:\n",
    "        # Plot generated molecules\n",
    "        ax.hist(property_distributions[prop], bins=10, alpha=0.7, \n",
    "                label='Generated', color='skyblue', density=True)\n",
    "        \n",
    "        # Plot reference molecules if available\n",
    "        if prop in reference_distributions and len(reference_distributions[prop]) > 0:\n",
    "            ax.hist(reference_distributions[prop], bins=10, alpha=0.7, \n",
    "                    label='Reference', color='orange', density=True)\n",
    "        \n",
    "        ax.set_xlabel(label)\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_title(f'Distribution of {label}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'No data for\\n{label}', \n",
    "                ha='center', va='center', transform=ax.transAxes)\n",
    "        ax.set_title(f'{label} (No Data)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QED score distribution\n",
    "qed_scores = evaluator.compute_qed_scores(unique_generated)\n",
    "valid_qed_scores = [score for score in qed_scores if score > 0]\n",
    "\n",
    "if valid_qed_scores:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(valid_qed_scores, bins=15, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    plt.axvline(np.mean(valid_qed_scores), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(valid_qed_scores):.3f}')\n",
    "    plt.axvline(0.5, color='orange', linestyle='--', \n",
    "                label='Drug-like threshold (0.5)')\n",
    "    plt.xlabel('QED Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of QED Scores (Drug-likeness)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid QED scores to plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lipinski compliance visualization\n",
    "lipinski_compliance = evaluator.compute_lipinski_compliance(unique_generated)\n",
    "\n",
    "if lipinski_compliance['lipinski_pass']:\n",
    "    # Calculate pass rates for each rule\n",
    "    rules = ['molecular_weight_ok', 'logp_ok', 'hbd_ok', 'hba_ok', 'lipinski_pass']\n",
    "    rule_labels = ['MW ≤ 500', 'LogP ≤ 5', 'HBD ≤ 5', 'HBA ≤ 10', 'All Rules']\n",
    "    pass_rates = [np.mean(lipinski_compliance[rule]) for rule in rules]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(rule_labels, pass_rates, color=['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightpink'])\n",
    "    plt.ylabel('Pass Rate')\n",
    "    plt.title('Lipinski Rule Compliance')\n",
    "    plt.ylim(0, 1.1)\n",
    "    \n",
    "    # Add percentage labels on bars\n",
    "    for bar, rate in zip(bars, pass_rates):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{rate:.1%}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No Lipinski compliance data to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Benchmarking {#benchmarking}\n",
    "\n",
    "Let's benchmark the generation performance and compare different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark generation speed\n",
    "def benchmark_generation(generator, num_molecules, batch_sizes, temperatures):\n",
    "    results = []\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        for temp in temperatures:\n",
    "            print(f\"Testing batch_size={batch_size}, temperature={temp}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            molecules = generator.generate(\n",
    "                num_molecules=num_molecules,\n",
    "                batch_size=batch_size,\n",
    "                temperature=temp,\n",
    "                max_attempts=3\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Validate molecules\n",
    "            valid_count = sum(1 for mol in molecules if generator.smiles_processor.validate_molecule(mol))\n",
    "            \n",
    "            results.append({\n",
    "                'batch_size': batch_size,\n",
    "                'temperature': temp,\n",
    "                'time': end_time - start_time,\n",
    "                'generated': len(molecules),\n",
    "                'valid': valid_count,\n",
    "                'validity_rate': valid_count / len(molecules) if molecules else 0,\n",
    "                'molecules_per_second': len(molecules) / (end_time - start_time)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmark\n",
    "benchmark_results = benchmark_generation(\n",
    "    generator=generator,\n",
    "    num_molecules=20,\n",
    "    batch_sizes=[2, 4, 8],\n",
    "    temperatures=[0.8, 1.0, 1.2]\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "benchmark_df = pd.DataFrame(benchmark_results)\n",
    "print(\"\\nBenchmark Results:\")\n",
    "print(benchmark_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize benchmark results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Generation speed vs batch size\n",
    "for temp in benchmark_df['temperature'].unique():\n",
    "    temp_data = benchmark_df[benchmark_df['temperature'] == temp]\n",
    "    axes[0].plot(temp_data['batch_size'], temp_data['molecules_per_second'], \n",
    "                marker='o', label=f'T={temp}')\n",
    "\n",
    "axes[0].set_xlabel('Batch Size')\n",
    "axes[0].set_ylabel('Molecules per Second')\n",
    "axes[0].set_title('Generation Speed vs Batch Size')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validity rate vs temperature\n",
    "for batch_size in benchmark_df['batch_size'].unique():\n",
    "    batch_data = benchmark_df[benchmark_df['batch_size'] == batch_size]\n",
    "    axes[1].plot(batch_data['temperature'], batch_data['validity_rate'], \n",
    "                marker='s', label=f'Batch={batch_size}')\n",
    "\n",
    "axes[1].set_xlabel('Temperature')\n",
    "axes[1].set_ylabel('Validity Rate')\n",
    "axes[1].set_title('Validity Rate vs Temperature')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory usage analysis (if CUDA is available)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Memory Usage Analysis:\")\n",
    "    \n",
    "    # Clear cache\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Measure memory before generation\n",
    "    memory_before = torch.cuda.memory_allocated() / 1024**2  # MB\n",
    "    \n",
    "    # Generate molecules\n",
    "    test_molecules = generator.generate(num_molecules=10, batch_size=5)\n",
    "    \n",
    "    # Measure memory after generation\n",
    "    memory_after = torch.cuda.memory_allocated() / 1024**2  # MB\n",
    "    memory_peak = torch.cuda.max_memory_allocated() / 1024**2  # MB\n",
    "    \n",
    "    print(f\"Memory before generation: {memory_before:.1f} MB\")\n",
    "    print(f\"Memory after generation: {memory_after:.1f} MB\")\n",
    "    print(f\"Peak memory usage: {memory_peak:.1f} MB\")\n",
    "    print(f\"Memory increase: {memory_after - memory_before:.1f} MB\")\n",
    "    \n",
    "    # Reset peak memory stats\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "else:\n",
    "    print(\"CUDA not available - skipping GPU memory analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "In this tutorial, we've covered:\n",
    "\n",
    "1. **Data Preparation**: Loading and processing molecular data\n",
    "2. **Model Training**: Training a diffusion model for molecular generation\n",
    "3. **Generation**: Generating molecules with different parameters\n",
    "4. **Constraint-based Generation**: Generating drug-like molecules\n",
    "5. **Evaluation**: Comprehensive evaluation of generated molecules\n",
    "6. **Visualization**: Creating plots to understand results\n",
    "7. **Benchmarking**: Performance analysis and optimization\n",
    "\n",
    "### Key Takeaways:\n",
    "- Temperature affects the diversity vs quality trade-off\n",
    "- Constraint-based generation helps produce drug-like molecules\n",
    "- Proper evaluation is crucial for understanding model performance\n",
    "- Batch size affects generation speed and memory usage\n",
    "\n",
    "### Next Steps:\n",
    "1. **Scale up**: Train on larger datasets (ZINC15, ChEMBL)\n",
    "2. **Advanced constraints**: Implement custom constraint functions\n",
    "3. **Property prediction**: Integrate property prediction models\n",
    "4. **Model comparison**: Compare different architectures (GraphAF vs GraphDiffusion)\n",
    "5. **Production deployment**: Set up model serving for applications\n",
    "\n",
    "### Resources:\n",
    "- [Advanced Generation Examples](advanced_generation.md)\n",
    "- [Production Deployment Guide](production_deployment.md)\n",
    "- [API Documentation](../docs/api/README.md)\n",
    "- [Best Practices](../docs/best_practices.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for future use\n",
    "results_summary = {\n",
    "    'training_results': results,\n",
    "    'evaluation_metrics': evaluation_results,\n",
    "    'drug_likeness_metrics': drug_likeness_metrics,\n",
    "    'benchmark_results': benchmark_df.to_dict('records'),\n",
    "    'generated_molecules': unique_generated,\n",
    "    'drug_molecules': drug_molecules\n",
    "}\n",
    "\n",
    "# Save to file (optional)\n",
    "import json\n",
    "output_file = 'tutorial_results.json'\n",
    "\n",
    "# Convert numpy arrays to lists for JSON serialization\n",
    "def convert_numpy(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    return obj\n",
    "\n",
    "# Clean results for JSON serialization\n",
    "clean_results = json.loads(json.dumps(results_summary, default=convert_numpy))\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(clean_results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")\n",
    "print(\"Tutorial completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}